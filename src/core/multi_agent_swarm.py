"""
Multi-Agent Swarm for Legal Knowledge Graph Construction

Three specialized agents that debate and construct a rich legal knowledge graph:
1. Linker Agent: Finds all citations (The Proposer)
2. Interpreter Agent: Classifies edge types (The Analyst)
3. Conflict Agent: Detects logical contradictions and cycles (The Critic)

Novel Contribution:
Implements a "Debate-Refine" loop where agents iteratively critique and improve
the citation graph to resolve logical inconsistencies (cycles, contradictions)
before finalizing the knowledge graph.
"""

from langchain_community.llms import Ollama
from typing import List, Dict, Tuple, Set, Optional
import re
from dataclasses import dataclass, field
from enum import Enum
import copy

# NEW: Import Nash equilibrium solver for Part 2 contribution
try:
    from theory.nash_equilibrium_formulation import NashEquilibriumSolver, Citation as NashCitation
    NASH_AVAILABLE = True
except ImportError:
    print("WARNING: Nash equilibrium solver not available")
    NASH_AVAILABLE = False


class EdgeType(Enum):
    """Types of legal citation relationships"""
    FOLLOW = "FOLLOW"  # Case A follows Case B (reinforces precedent)
    DISTINGUISH = "DISTINGUISH"  # Case A distinguishes from Case B (creates fork)
    OVERRULE = "OVERRULE"  # Case A overrules Case B (inverts authority)
    SUPPORTS = "SUPPORTS"  # Generic support relationship
    ATTACKS = "ATTACKS"  # Argument attacks another
    PROVIDES_WARRANT = "PROVIDES_WARRANT"  # Provides legal warrant


@dataclass
class Citation:
    """A citation from one case to another"""
    source_id: str
    target_id: str
    context: str  # Text surrounding the citation
    edge_type: EdgeType = EdgeType.SUPPORTS
    confidence: float = 0.5
    
    def __hash__(self):
        return hash((self.source_id, self.target_id))
    
    def __eq__(self, other):
        return self.source_id == other.source_id and self.target_id == other.target_id


@dataclass
class Conflict:
    """A logical conflict in the graph"""
    conflict_type: str  # "cycle", "contradiction", "overrule_chain"
    involved_cases: List[str]
    description: str
    severity: float  # 0.0 to 1.0


@dataclass
class Critique:
    """Actionable feedback generated by the Conflict Agent"""
    target_source: str
    target_target: str
    issue_type: str
    message: str
    suggestion: str  # "REMOVE", "DOWNGRADE", "RECLASSIFY"
    severity: float


class LinkerAgent:
    """
    Agent 1: Finds all citations in case text.
    
    Uses both pattern matching and LLM reasoning to identify when
    one case references another.
    """
    
    def __init__(self, llm):
        self.llm = llm
        self.name = "Linker Agent"
    
    def find_citations(self, case_id: str, case_text: str, all_case_ids: Set[str]) -> List[Citation]:
        """
        Find all citations in the case text.
        
        Strategy:
        1. Pattern matching for obvious citations
        2. LLM to identify contextual references
        """
        citations = []
        
        # Pattern matching (fast)
        patterns = [
            r'(?:AIR|SCC)\s+\d{4}\s+[A-Z]+\s+\d+',  # AIR 2019 SC 123
            r'\(\d{4}\)\s+\d+\s+SCC\s+\d+',  # (2018) 10 SCC 456
            r'(?:v\.|vs\.)\s+[A-Z][a-z]+\s+\(\d{4}\)',  # v. Kumar (2020)
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, case_text[:5000])
            for match in matches:
                # Try to match to actual case IDs
                for target_id in all_case_ids:
                    if self._fuzzy_match(match, target_id) and target_id != case_id:
                        # Get context (50 chars before and after)
                        idx = case_text.find(match)
                        context = case_text[max(0, idx-50):min(len(case_text), idx+len(match)+50)]
                        
                        citations.append(Citation(
                            source_id=case_id,
                            target_id=target_id,
                            context=context,
                            confidence=0.8
                        ))
                        break
        
        # LLM reasoning (slower but more accurate)
        if len(citations) < 3:  # If pattern matching found few, use LLM
            citations.extend(self._llm_find_citations(case_id, case_text, all_case_ids))
        
        # Remove duplicates
        unique_citations = []
        seen = set()
        for c in citations:
            key = (c.source_id, c.target_id)
            if key not in seen:
                seen.add(key)
                unique_citations.append(c)
                
        return unique_citations
    
    def _fuzzy_match(self, citation_str: str, case_id: str) -> bool:
        """Check if citation string matches case ID"""
        citation_lower = citation_str.lower()
        case_id_lower = case_id.lower()
        
        # Extract numbers from both
        citation_nums = set(re.findall(r'\d+', citation_str))
        case_nums = set(re.findall(r'\d+', case_id))
        
        # Match if they share numbers and some text
        return len(citation_nums & case_nums) > 0 or citation_lower in case_id_lower
    
    def _llm_find_citations(self, case_id: str, case_text: str, all_case_ids: Set[str]) -> List[Citation]:
        """Use LLM to find citations"""
        # Simplified for speed
        sample = case_text[:1500]
        
        prompt = f"""List case citations found in this text. Output format: one citation per line.

TEXT: {sample}

CITATIONS:"""
        
        try:
            response = self.llm.invoke(prompt)
            lines = str(response).split('\n')
            
            citations = []
            for line in lines:
                if len(line.strip()) > 5:
                    # Try to match to real case IDs
                    for target_id in all_case_ids:
                        if target_id != case_id and self._fuzzy_match(line, target_id):
                            citations.append(Citation(
                                source_id=case_id,
                                target_id=target_id,
                                context=line,
                                confidence=0.6
                            ))
                            break
            
            return citations[:5]
        except:
            return []


class InterpreterAgent:
    """
    Agent 2: Interprets citation context to classify edge types.
    
    Determines if a citation is:
    - FOLLOW: Case A agrees with and follows Case B
    - DISTINGUISH: Case A distinguishes facts from Case B
    - OVERRULE: Case A explicitly overrules Case B
    """
    
    def __init__(self, llm):
        self.llm = llm
        self.name = "Interpreter Agent"
    
    def classify_citation(self, citation: Citation) -> Citation:
        """
        Classify the type of citation based on context.
        
        Uses LLM to analyze the textual context around the citation.
        """
        context = citation.context
        
        # Quick heuristics first
        if any(word in context.lower() for word in ['overrule', 'overruled', 'reversed', 'set aside']):
            citation.edge_type = EdgeType.OVERRULE
            citation.confidence = 0.9
            return citation
        
        if any(word in context.lower() for word in ['distinguish', 'different facts', 'inapplicable', 'not applicable']):
            citation.edge_type = EdgeType.DISTINGUISH
            citation.confidence = 0.85
            return citation
        
        if any(word in context.lower() for word in ['follow', 'relied upon', 'precedent', 'in line with', 'affirmed']):
            citation.edge_type = EdgeType.FOLLOW
            citation.confidence = 0.8
            return citation
        
        # Use LLM for unclear cases
        try:
            edge_type, confidence = self._llm_classify(context)
            citation.edge_type = edge_type
            citation.confidence = confidence
        except:
            # Default to SUPPORTS
            citation.edge_type = EdgeType.SUPPORTS
            citation.confidence = 0.5
        
        return citation
    
    def _llm_classify(self, context: str) -> Tuple[EdgeType, float]:
        """Use LLM to classify citation type"""
        prompt = f"""Classify this legal citation context:

CONTEXT: "{context}"

Is this:
A) FOLLOW - The case follows/agrees with the cited case
B) DISTINGUISH - The case distinguishes from the cited case  
C) OVERRULE - The case overrules the cited case

Answer with only A, B, or C:"""
        
        response = str(self.llm.invoke(prompt)).strip().upper()
        
        if 'A' in response or 'FOLLOW' in response:
            return EdgeType.FOLLOW, 0.75
        elif 'B' in response or 'DISTINGUISH' in response:
            return EdgeType.DISTINGUISH, 0.75
        elif 'C' in response or 'OVERRULE' in response:
            return EdgeType.OVERRULE, 0.75
        else:
            return EdgeType.SUPPORTS, 0.5


class ConflictAgent:
    """
    Agent 3: Detects logical conflicts in the citation graph.
    
    Identifies:
    - Cycles: A cites B, B cites C, C cites A
    - Contradictions: A follows B, but A also overrules B
    - Overrule chains: A overrules B, B overrules C
    """
    
    def __init__(self):
        self.name = "Conflict Agent"
    
    def find_conflicts(self, citations: List[Citation]) -> List[Conflict]:
        """
        Analyze the citation network for logical conflicts.
        """
        conflicts = []
        
        # Build adjacency lists
        graph = {}
        for cit in citations:
            if cit.source_id not in graph:
                graph[cit.source_id] = []
            graph[cit.source_id].append((cit.target_id, cit.edge_type))
        
        # Detect cycles
        cycles = self._find_cycles(graph)
        for cycle in cycles:
            conflicts.append(Conflict(
                conflict_type="cycle",
                involved_cases=cycle,
                description=f"Citation cycle detected: {' -> '.join(cycle)}",
                severity=0.6
            ))
        
        # Detect contradictory edges
        contradictions = self._find_contradictions(citations)
        conflicts.extend(contradictions)
        
        # Detect overrule chains
        overrule_chains = self._find_overrule_chains(citations)
        conflicts.extend(overrule_chains)
        
        return conflicts
    
    def generate_critiques(self, conflicts: List[Conflict], citations: List[Citation]) -> List[Critique]:
        """
        Convert conflicts into actionable critiques for the other agents.
        """
        critiques = []
        
        for conflict in conflicts:
            if conflict.conflict_type == "cycle":
                # For cycles, suggest removing the weakest link (lowest confidence)
                # This is a heuristic, but effective
                cycle_nodes = set(conflict.involved_cases)
                cycle_edges = [
                    c for c in citations 
                    if c.source_id in cycle_nodes and c.target_id in cycle_nodes
                ]
                if cycle_edges:
                    # Find weakest edge
                    weakest = min(cycle_edges, key=lambda x: x.confidence)
                    critiques.append(Critique(
                        target_source=weakest.source_id,
                        target_target=weakest.target_id,
                        issue_type="cycle",
                        message=f"Cycle detected involving {weakest.source_id}. This edge has lowest confidence ({weakest.confidence}).",
                        suggestion="REMOVE",
                        severity=conflict.severity
                    ))
            
            elif conflict.conflict_type == "contradiction":
                # For contradictions (e.g. Follow AND Overrule), suggest re-checking context
                src, tgt = conflict.involved_cases[0], conflict.involved_cases[1]
                critiques.append(Critique(
                    target_source=src,
                    target_target=tgt,
                    issue_type="contradiction",
                    message=f"Contradictory relationship between {src} and {tgt}.",
                    suggestion="RECLASSIFY",
                    severity=conflict.severity
                ))
                
        return critiques
    
    def _find_cycles(self, graph: Dict) -> List[List[str]]:
        """Find cycles using DFS"""
        cycles = []
        visited = set()
        rec_stack = set()
        path = []
        
        def dfs(node):
            visited.add(node)
            rec_stack.add(node)
            path.append(node)
            
            if node in graph:
                for neighbor, _ in graph[node]:
                    if neighbor not in visited:
                        dfs(neighbor)
                    elif neighbor in rec_stack:
                        # Found cycle
                        cycle_start = path.index(neighbor)
                        cycles.append(path[cycle_start:] + [neighbor])
            
            path.pop()
            rec_stack.remove(node)
        
        for node in graph:
            if node not in visited:
                dfs(node)
        
        return cycles[:5]  # Return first 5 cycles
    
    def _find_contradictions(self, citations: List[Citation]) -> List[Conflict]:
        """Find contradictory edge types between same nodes"""
        conflicts = []
        edge_map = {}
        
        for cit in citations:
            key = (cit.source_id, cit.target_id)
            if key not in edge_map:
                edge_map[key] = []
            edge_map[key].append(cit.edge_type)
        
        for (src, tgt), edge_types in edge_map.items():
            unique_types = set(edge_types)
            
            # Check for contradictions
            if EdgeType.FOLLOW in unique_types and EdgeType.OVERRULE in unique_types:
                conflicts.append(Conflict(
                    conflict_type="contradiction",
                    involved_cases=[src, tgt],
                    description=f"{src} both follows AND overrules {tgt}",
                    severity=0.9
                ))
        
        return conflicts
    
    def _find_overrule_chains(self, citations: List[Citation]) -> List[Conflict]:
        """Find chains of overruling decisions"""
        overrules = [(c.source_id, c.target_id) for c in citations if c.edge_type == EdgeType.OVERRULE]
        
        conflicts = []
        for i, (a, b) in enumerate(overrules):
            for j, (c, d) in enumerate(overrules):
                if i != j and b == c:  # A overrules B, B overrules D
                    conflicts.append(Conflict(
                        conflict_type="overrule_chain",
                        involved_cases=[a, b, d],
                        description=f"Overrule chain: {a} ‚Üí {b} ‚Üí {d}",
                        severity=0.7
                    ))
        
        return conflicts[:3]


class MultiAgentSwarm:
    """
    Orchestrates the three agents to build the knowledge graph.
    
    Workflow:
    1. Linker Agent finds all citations
    2. Interpreter Agent classifies each citation
    3. Conflict Agent identifies graph inconsistencies
    4. Agents "debate" conflicts and reach consensus
    """
    
    def __init__(self):
        # Use Gemma 2 2B - faster than DeepSeek
        llm = Ollama(model="gemma2:2b", temperature=0.3, num_predict=200)
        
        self.linker = LinkerAgent(llm)
        self.interpreter = InterpreterAgent(llm)
        self.conflict = ConflictAgent()
        
        # NEW: Nash equilibrium solver for game-theoretic coordination
        if NASH_AVAILABLE:
            self.nash_solver = NashEquilibriumSolver(lambda_penalty=0.1)
            self.use_nash = True
            print("‚úì Multi-Agent Swarm initialized (with Nash Equilibrium)")
        else:
            self.nash_solver = None
            self.use_nash = False
            print("‚úì Multi-Agent Swarm initialized (standard debate mode)")
        
        print(f"  - {self.linker.name} (Proposer)")
        print(f"  - {self.interpreter.name} (Analyst)")
        print(f"  - {self.conflict.name} (Critic)")
    
    def process_case_with_debate(self, case_text: str, case_id: str, all_case_ids: Set[str] = None, max_rounds: int = 3) -> Dict:
        """
        Process a single case through the multi-agent swarm with Iterative Debate.
        
        Args:
            case_text: Full text of the case
            case_id: Unique identifier for this case
            all_case_ids: Set of all available case IDs for citation matching
            max_rounds: Maximum number of debate/refinement rounds
        
        Returns:
            Dict with 'citations' and 'conflicts' keys
        """
        if all_case_ids is None:
            all_case_ids = set()
            
        print(f"\nüîÑ Starting Debate Loop for Case {case_id[:20]}... (Max {max_rounds} rounds)")
        
        # Round 0: Initial Proposal
        print("  Round 1: Linker proposing citations...")
        citations = self.linker.find_citations(case_id, case_text, all_case_ids)
        
        # Initial Classification
        for i, c in enumerate(citations):
            citations[i] = self.interpreter.classify_citation(c)
            
        final_conflicts = []
        
        # Debate Loop
        for round_num in range(1, max_rounds + 1):
            print(f"  Round {round_num} Analysis: Checking {len(citations)} citations for conflicts...")
            
            # Conflict Agent Critiques
            conflicts = self.conflict.find_conflicts(citations)
            critiques = self.conflict.generate_critiques(conflicts, citations)
            
            if not critiques:
                print("  ‚úÖ Consensus reached! No conflicts found.")
                final_conflicts = []
                break
            
            print(f"  ‚ö†Ô∏è  Round {round_num} Critique: Found {len(critiques)} issues.")
            for c in critiques:
                print(f"     - {c.message} -> Suggestion: {c.suggestion}")
            
            # If we are at the last round, we accept the conflicts and stop
            if round_num == max_rounds:
                print("  üõë Max rounds reached. Finalizing with remaining conflicts.")
                final_conflicts = conflicts
                break
                
            # Refinement Step
            print("  üõ†Ô∏è  Refining graph based on critiques...")
            citations = self.refine_citations(citations, critiques)
            
        return {
            'citations': citations,
            'conflicts': final_conflicts
        }
    
    def refine_citations(self, citations: List[Citation], critiques: List[Critique]) -> List[Citation]:
        """
        Apply critiques to refine the citation list.
        """
        refined_citations = copy.deepcopy(citations)
        
        for critique in critiques:
            # Find the target citation
            target = next((c for c in refined_citations 
                           if c.source_id == critique.target_source 
                           and c.target_id == critique.target_target), None)
            
            if target:
                if critique.suggestion == "REMOVE":
                    print(f"     -> Removing citation {target.source_id} -> {target.target_id}")
                    refined_citations.remove(target)
                
                elif critique.suggestion == "DOWNGRADE":
                    print(f"     -> Downgrading confidence for {target.source_id} -> {target.target_id}")
                    target.confidence *= 0.8
                    
                elif critique.suggestion == "RECLASSIFY":
                    # For now, default to SUPPORTS if contradictory
                    print(f"     -> Reclassifying {target.source_id} -> {target.target_id} to SUPPORTS")
                    target.edge_type = EdgeType.SUPPORTS
                    target.confidence *= 0.9
                    
        return refined_citations

    def build_knowledge_graph(self, cases: List[Dict]) -> Tuple[List[Citation], List[Conflict]]:
        """
        Build knowledge graph through agent collaboration.
        """
        print(f"\n{'='*80}")
        print("MULTI-AGENT SWARM: BUILDING KNOWLEDGE GRAPH (WITH DEBATE)")
        print(f"{'='*80}\n")
        
        all_case_ids = set([c['id'] for c in cases])
        all_citations = []
        all_conflicts = []
        
        for i, case in enumerate(cases):
            print(f"\nProcessing Case [{i+1}/{len(cases)}]: {case['id'][:40]}")
            
            result = self.process_case_with_debate(case['text'], case['id'], all_case_ids)
            
            all_citations.extend(result['citations'])
            all_conflicts.extend(result['conflicts'])
        
        print(f"\n{'='*80}")
        print("FINAL GRAPH STATISTICS")
        print(f"  ‚úì Total Citations: {len(all_citations)}")
        print(f"  ‚úì Unresolved Conflicts: {len(all_conflicts)}")
        
        return all_citations, all_conflicts
    
    def process_case_with_nash_equilibrium(self, case_text: str, case_id: str, 
                                           all_case_ids: Set[str] = None,
                                           ground_truth: List[Citation] = None) -> Dict:
        """
        NEW METHOD for Part 2: Process case using Nash equilibrium instead of debate.
        
        This provides theoretical grounding for multi-agent coordination.
        Instead of ad-hoc iterative refinement, we find Nash equilibrium
        where no agent can improve their payoff by changing strategy.
        
        Args:
            case_text: Full text of the case
            case_id: Unique identifier
            all_case_ids: Set of all case IDs for citation matching
            ground_truth: Ground truth citations (for evaluation)
        
        Returns:
            Dict with 'citations', 'equilibrium_history', 'payoffs'
        """
        if not self.use_nash:
            print("‚ö†Ô∏è  Nash solver not available, falling back to debate")
            return self.process_case_with_debate(case_text, case_id, all_case_ids)
        
        if all_case_ids is None:
            all_case_ids = set()
        
        print(f"\nüéÆ Nash Equilibrium Mode for Case {case_id[:20]}...")
        
        # Phase 1: Initial proposals from agents
        print("  Phase 1: Agents propose initial strategies...")
        citations = self.linker.find_citations(case_id, case_text, all_case_ids)
        
        for i, c in enumerate(citations):
            citations[i] = self.interpreter.classify_citation(c)
        
        conflicts = self.conflict.find_conflicts(citations)
        
        # Phase 2: Find Nash equilibrium
        print("  Phase 2: Finding Nash equilibrium...")
        
        # Convert to Nash solver format
        initial_graph = {
            'citations': [
                NashCitation(
                    source_id=c.source_id,
                    target_id=c.target_id,
                    edge_type=c.edge_type.value,
                    confidence=c.confidence,
                    context=c.context
                )
                for c in citations
            ]
        }
        
        # Convert ground truth if provided
        nash_ground_truth = None
        if ground_truth:
            nash_ground_truth = {
                'citations': [
                    NashCitation(
                        source_id=c.source_id,
                        target_id=c.target_id,
                        edge_type=c.edge_type.value,
                        confidence=c.confidence,
                        context=c.context
                    )
                    for c in ground_truth
                ]
            }
        
        # Find equilibrium
        equilibrium_graph, equilibrium_history = self.nash_solver.find_nash_equilibrium(
            initial_graph,
            max_iterations=5,
            ground_truth=nash_ground_truth
        )
        
        # Convert back to standard Citation format
        final_citations = [
            Citation(
                source_id=c.source_id,
                target_id=c.target_id,
                context=c.context,
                edge_type=EdgeType(c.edge_type),
                confidence=c.confidence
            )
            for c in equilibrium_graph['citations']
        ]
        
        # Compute final payoffs
        final_payoffs = self.nash_solver.compute_joint_payoff(equilibrium_graph, nash_ground_truth)
        
        print(f"  ‚úì Equilibrium reached in {len(equilibrium_history)} iterations")
        print(f"  Final payoffs: Linker={final_payoffs['linker']:.3f}, "
              f"Interpreter={final_payoffs['interpreter']:.3f}, "
              f"Conflict={final_payoffs['conflict']:.3f}")
        
        return {
            'citations': final_citations,
            'equilibrium_history': equilibrium_history,
            'payoffs': final_payoffs,
            'method': 'nash_equilibrium'
        }
